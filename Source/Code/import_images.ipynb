{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/orobix/opt/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = '../Data/CT/'\n",
    "MRI = '../Data/MRI/'\n",
    "PET = '../Data/PET/'\n",
    "\n",
    "myPaths = [CT, MRI, PET]\n",
    "myDict = {CT:[], MRI:[], PET:[]}\n",
    "\n",
    "#images file names dictionary\n",
    "for path in myPaths:\n",
    "    myDict[path] = [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 744 = 70 %\n",
      "Number of validation images: 213 = 20 %\n",
      "Number of test images: 108 = 10 %\n"
     ]
    }
   ],
   "source": [
    "#70:20:10 \n",
    "train_size=0.7\n",
    "val_size=0.2\n",
    "\n",
    "#split train test\n",
    "CT_train, CT_test = train_test_split(myDict[myPaths[0]], train_size=0.70)\n",
    "MRI_train, MRI_test = train_test_split(myDict[myPaths[1]], train_size=0.70)\n",
    "PET_train, PET_test = train_test_split(myDict[myPaths[2]], train_size=0.70)\n",
    "\n",
    "#split train validation\n",
    "CT_val, CT_test = train_test_split(CT_test, train_size=(val_size)/(1-train_size))\n",
    "MRI_val, MRI_test = train_test_split(MRI_test, train_size=(val_size)/(1-train_size))\n",
    "PET_val, PET_test = train_test_split(PET_test, train_size=(val_size)/(1-train_size))\n",
    "\n",
    "#create list of file names\n",
    "train_file_names = CT_train + MRI_train + PET_train\n",
    "val_file_names = CT_val + MRI_val + PET_val\n",
    "test_file_names = CT_test + MRI_test + PET_test\n",
    "\n",
    "#print dimensions datasets\n",
    "lenTot = len(train_file_names)+len(val_file_names)+len(test_file_names)\n",
    "percTrain = (len(train_file_names)/lenTot)*100\n",
    "percVal = (len(val_file_names)/lenTot)*100\n",
    "percTest = (len(test_file_names)/lenTot)*100\n",
    "print('Number of train images:', len(train_file_names), '= %.0f' % percTrain,'%')\n",
    "print('Number of validation images:', len(val_file_names), '= %.0f' % percVal,'%')\n",
    "print('Number of test images:', len(test_file_names), '= %.0f' % percTest,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data/ and copy images in train/, val/ and test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/orobix/Documents/Thesis/Source/Code\n",
      "Delete complete\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "#delete existing data/\n",
    "data_dir = 'data/'\n",
    "if os.path.exists(data_dir):\n",
    "    print('Deleting', data_dir)\n",
    "    try:\n",
    "        shutil.rmtree(data_dir)\n",
    "    except:\n",
    "        raise\n",
    "print('Delete complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data/ here: /Users/orobix/Documents/Thesis/Source/Code\n"
     ]
    }
   ],
   "source": [
    "#make data/\n",
    "print('Creating', data_dir, 'here:', os.getcwd())\n",
    "\n",
    "directories = ['data/train/', \n",
    "               'data/val/', \n",
    "               'data/test/']\n",
    "\n",
    "#make\n",
    "for directory in directories:\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy images in relative dir\n",
    "_file_names = [train_file_names, val_file_names, test_file_names] \n",
    "\n",
    "def copyImages(srcs, _file_names, directory):\n",
    "    for source in srcs:\n",
    "        for f in _file_names:\n",
    "            try:\n",
    "                shutil.copy(source+f, directory)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "for name,directory in zip(_file_names, directories):\n",
    "    copyImages(myPaths, name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
