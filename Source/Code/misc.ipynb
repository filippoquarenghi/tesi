{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    input_img = Input(shape=(dims[0],), name='input')\n",
    "    x = input_img\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "    # hidden layer\n",
    "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
    "\n",
    "    x = encoded\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "    # output\n",
    "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "    decoded = x\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function for reshaping arrays for DenseAutoEncoder\n",
    "def ReshapeDAE(array):\n",
    "    array = array.reshape(array.shape[0], -1)\n",
    "    array = array/255.\n",
    "    return array\n",
    "\n",
    "#scegli la funzione\n",
    "f = ReshapeDAE\n",
    "\n",
    "x_train = f(x_train)\n",
    "x_val = f(x_val)\n",
    "x_test = f(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "dims = [x.shape[-1], 500, 500, 2000, 3]\n",
    "print(dims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS THE AUTOENCODER CON IL DENSE PRIMA DELL'EMBEDDED E DOPO L'EMBEDDED: il train ha data come risultati delle immagini schifo (vedi risultati_autoencoder_schifo.png)\n",
    "\n",
    "\n",
    "\n",
    "def autoencoderConv2D_1(input_shape=(128, 128, 1), filters=[32, 64, 128, 256, 3]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(units=filters[3])(x) ##\n",
    "    \n",
    "    encoded = Dense(units=filters[4], name='embedding')(x)\n",
    "    \n",
    "    x = Dense(units=filters[3], activation='relu')(encoded)\n",
    "    \n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(x) ##\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    \n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoderConv2D_1(input_shape=(128, 128, 1), filters=[32, 64, 128, 256, 3]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    \n",
    "    y = Dense(units=filters[4])(encoded)\n",
    "    \n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    \n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=y, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 8,515,587\n",
      "Trainable params: 8,515,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "AUTOENCODER\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32768)             8421376   \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "deconv3 (Conv2DTranspose)    (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 64, 64, 32)        51232     \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 128, 128, 1)       801       \n",
      "=================================================================\n",
      "Total params: 17,062,017\n",
      "Trainable params: 17,062,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = autoencoderConv2D_1()\n",
    "\n",
    "print('ENCODER')\n",
    "encoder.summary()\n",
    "\n",
    "print('AUTOENCODER')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
