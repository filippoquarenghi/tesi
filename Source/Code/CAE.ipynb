{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = '../Data/CT/'\n",
    "MRI = '../Data/MRI/'\n",
    "PET = '../Data/PET/'\n",
    "\n",
    "myPaths = [CT, MRI, PET]\n",
    "myDict = {CT:[], MRI:[], PET:[]}\n",
    "\n",
    "#creo il dizionario con le liste delle immagini\n",
    "for path in myPaths:\n",
    "    myDict[path] = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "#split train test (0.7 con data augmentation, 0.8 altrimenti)\n",
    "split_at = 0.7\n",
    "\n",
    "CT_train, CT_test = train_test_split(myDict[myPaths[0]], train_size=split_at)\n",
    "MRI_train, MRI_test = train_test_split(myDict[myPaths[1]], train_size=split_at)\n",
    "PET_train, PET_test = train_test_split(myDict[myPaths[2]], train_size=split_at)\n",
    "\n",
    "#split train validation\n",
    "#CT_train, CT_validation = train_test_split(CT_train, train_size=split_at)\n",
    "#MRI_train, MRI_validation = train_test_split(MRI_train, train_size=split_at)\n",
    "#PET_train, PET_validation = train_test_split(PET_train, train_size=split_at)\n",
    "\n",
    "#print(train_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "print('Creo la directory data/ in questa posizione:', os.getcwd())\n",
    "\n",
    "directories = ['data/train/', \n",
    "               #'data/validation', \n",
    "               'data/test/']\n",
    "\n",
    "#cancello directory precedente per evitare errori\n",
    "if os.path.exists('data/'):\n",
    "    shutil.rmtree('data/', ignore_errors=False) \n",
    "\n",
    "#creo le direcotories data/train, data/test\n",
    "for directory in directories:\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = ['CT', 'MRI', 'PET']\n",
    "\n",
    "#copio le immagini di train in data/train\n",
    "for source,scan in zip(myPaths, scans):\n",
    "    train_files = eval(scan+'_train')\n",
    "    for f in train_files:\n",
    "        shutil.copy(source+f, directories[0])\n",
    "        \n",
    "#copio le immagini di test in data/test\n",
    "for source,scan in zip(myPaths, scans):\n",
    "    test_files = eval(scan+'_test')\n",
    "    for f in test_files:\n",
    "        shutil.copy(source+f, directories[1])\n",
    "print(\"Dati trasferiti con successo in data/train e data/test.\")\n",
    "\n",
    "#uncomment if you want unbalanced dataset\n",
    "#train_file_names = CT_train + MRI_train + PET_train\n",
    "#test_file_names = CT_test + MRI_test + PET_test\n",
    "\n",
    "#comment if you want unbalanced dataset\n",
    "minimum_len = min(len(CT_train),len(MRI_train),len(PET_train))        \n",
    "train_file_names = CT_train[0:minimum_len] + MRI_train[0:minimum_len] + PET_train[0:minimum_len]\n",
    "test_file_names = CT_test[0:minimum_len] + MRI_test[0:minimum_len] + PET_test[0:minimum_len]\n",
    "\n",
    "print(\"Number of images before data augmentation. Training:\", len(train_file_names), \" Test:\", len(test_file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation on train database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "def vertical_flip(image_array: ndarray):\n",
    "    # vertical flip\n",
    "    return image_array[::-1, :]\n",
    "\n",
    "def blured_image(image_array: ndarray):\n",
    "    return ndimage.uniform_filter(original_image, size=(11, 11, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# our folder path containing some images\n",
    "folder_path = 'data/train'\n",
    "\n",
    "# the number of file to generate\n",
    "num_files_desired = len(train_file_names)*2\n",
    "\n",
    "\n",
    "# loop on all files of the folder and build a list of files paths\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'noise': random_noise,\n",
    "    'horizontal_flip': horizontal_flip}\n",
    "\n",
    "for i in range(num_files_desired):\n",
    "    # random image from the folder\n",
    "    image_path = random.choice(images)\n",
    "    # read image as an two dimensional array of pixels\n",
    "    image_to_transform = sk.io.imread(image_path)\n",
    "    \n",
    "    # random num of transformations to apply\n",
    "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "    # choose a random transformation to apply for a single image\n",
    "    key = random.choice(list(available_transformations))\n",
    "    transformed_image = available_transformations[key](image_to_transform)\n",
    "    \n",
    "    # define a name for our new file\n",
    "    new_file_path = '%s_augmented_image_%s.png' % (image_path.split('.')[0], i)\n",
    "    \n",
    "    # write image to the disk\n",
    "    sk.io.imsave(new_file_path, transformed_image)\n",
    "    \n",
    "    #from IPython.core.debugger import set_trace\n",
    "    #set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converto le immagini nella cartella train in tensori e li concateno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# lista per fare image reading\n",
    "final_train_file_names = [os.path.join(directories[0], f) for f in os.listdir(directories[0]) if os.path.isfile(os.path.join(directories[0], f))]\n",
    "final_test_file_names = [os.path.join(directories[1], f) for f in os.listdir(directories[1]) if os.path.isfile(os.path.join(directories[1], f))]\n",
    "\n",
    "print(\"Database dimension after data augmentation. Training:\", len(final_train_file_names), \" Test:\", len(final_test_file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train\n",
    "x_train = io.imread(final_train_file_names[random.randint(0,9)])\n",
    "x_train = cv2.resize(x_train, dsize=(128,128))\n",
    "plt.imshow(x_train, cmap=plt.cm.gray)\n",
    "\n",
    "#stack images\n",
    "for img in final_train_file_names[1:]: #parti dalla seconda immagine\n",
    "    img = io.imread(img)\n",
    "    img = cv2.resize(img, dsize=(128,128))\n",
    "    x_train = np.dstack((x_train,img))\n",
    "\n",
    "x_train = np.rollaxis(x_train,-1) #(182,218,N)->(N,182,218)\n",
    "#print('x_train shape:',x_train.shape)\n",
    "    \n",
    "\n",
    "#x_test\n",
    "x_test = io.imread(final_test_file_names[random.randint(0,9)])\n",
    "x_test = cv2.resize(x_test, dsize=(128,128))\n",
    "plt.imshow(x_test, cmap=plt.cm.gray)\n",
    "\n",
    "#stack images\n",
    "for img in final_test_file_names[1:]: #parti dalla seconda immagine\n",
    "    img = io.imread(img)\n",
    "    img = cv2.resize(img, dsize=(128,128))\n",
    "    x_test = np.dstack((x_test,img))\n",
    "\n",
    "x_test = np.rollaxis(x_test,-1) #(182,218,N)->(N,182,218)\n",
    "#print('x_test shape:',x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make labels y for metrics: CT==0, MRI==1, PET==2\n",
    "ext = '.png'\n",
    "y_train = []\n",
    "for text in listdir('data/train'):\n",
    "    fileNameOnly = text[:text.find(ext)]\n",
    "    y_train.append(''.join([i for i in fileNameOnly if not i.isdigit()]))\n",
    "for i, item in enumerate(y_train):\n",
    "    if item == 'CT':\n",
    "        y_train[i] = 0\n",
    "    elif item == 'MRI':\n",
    "        y_train[i] = 1\n",
    "    else: y_train[i] = 2        \n",
    "\n",
    "#make labels y for metrics: CT==0, MRI==1, PET==2\n",
    "ext = '.png'\n",
    "y_test = []\n",
    "for text in listdir('data/test'):\n",
    "    fileNameOnly = text[:text.find(ext)]\n",
    "    y_test.append(''.join([i for i in fileNameOnly if not i.isdigit()]))\n",
    "for i, item in enumerate(y_test):\n",
    "    if item == 'CT':\n",
    "        y_test[i] = 0\n",
    "    elif item == 'MRI':\n",
    "        y_test[i] = 1\n",
    "    else: y_test[i] = 2  \n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.concatenate((x_train,x_test))\n",
    "#y = np.concatenate((y_train,y_test))\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "x_test = x_test/255.\n",
    "\n",
    "x = np.concatenate((x_train,))      \n",
    "y = np.concatenate((y_train,))\n",
    "\n",
    "x = x.reshape(x.shape + (1,))\n",
    "x = x/255.\n",
    "print('x shape:', x.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "#numero di clusters. (3)\n",
    "n_clusters = len(np.unique(y))\n",
    "print('Number of categories:', n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain a convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    input_img = Input(shape=(dims[0],), name='input')\n",
    "    x = input_img\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "    # hidden layer\n",
    "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
    "\n",
    "    x = encoded\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "    # output\n",
    "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "    decoded = x\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "         Measure the similarity between embedded point z_i and centroid µ_j.\n",
    "                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modello AE Conv2D_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoderConv2D_1(input_shape=(128, 128, 1), filters=[32, 64, 128, 27]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoderConv2D_1()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters (to edit)\n",
    "dims = [x.shape[-1], 500, 500, 2000, 3]\n",
    "\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "\n",
    "pretrain_optimizer = SGD(lr=1, momentum=0.9)\n",
    "\n",
    "pretrain_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = './results'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(x, \n",
    "                x, \n",
    "                batch_size=batch_size, \n",
    "                epochs=pretrain_epochs, \n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "\n",
    "autoencoder.save_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "#autoencoder.fit(x, x_out, batch_size=batch_size, epochs=pretrain_epochs)\n",
    "#autoencoder.save_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input,outputs=[clustering_layer, autoencoder.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x))\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing an auxiliary target distribution\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T\n",
    "\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 1400\n",
    "update_interval = 140\n",
    "index_array = np.arange(x.shape[0])\n",
    "\n",
    "tol = 0.00001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(x, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(metrics.acc(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.nmi(y, y_pred), 5)\n",
    "            ari = np.round(metrics.ari(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x=x[idx], y=[p[idx], x[idx]])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/b_DEC_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(save_dir + '/b_DEC_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval\n",
    "q, _ = model.predict(x, verbose=0)\n",
    "p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "# evaluate the clustering performance\n",
    "y_pred = q.argmax(1)\n",
    "if y is not None:\n",
    "    acc = np.round(metrics.acc(y, y_pred), 5)\n",
    "    nmi = np.round(metrics.nmi(y, y_pred), 5)\n",
    "    ari = np.round(metrics.ari(y, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('Acc = %.5f, nmi = %.5f, ari = %.5f' % (acc, nmi, ari), ' ; loss=', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=3)\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix([int(i) for i in y], y_pred)\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\n",
    "plt.title(\"Confusion matrix\", fontsize=30)\n",
    "plt.ylabel('True label', fontsize=25)\n",
    "plt.xlabel('Clustering label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "\n",
    "y_true = y.astype(np.int64)\n",
    "D = max(y_pred.max(), y_true.max()) + 1\n",
    "w = np.zeros((D, D), dtype=np.int64)\n",
    "# Confusion matrix.\n",
    "for i in range(y_pred.size):\n",
    "    w[y_pred[i], y_true[i]] += 1\n",
    "ind = linear_assignment(-w)\n",
    "\n",
    "sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "decoded_imgs = autoencoder.predict(x)\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
